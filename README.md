# Physics-Informed Deep Learning Super-Resolution for Semiconductor Inspection

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.1.0-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

> **Master's Thesis Research Project**
> Bridging the resolution gap between optical and electron microscopy in semiconductor manufacturing through physics-informed deep learning.

---

## ğŸ¯ Project Overview

This research investigates physics-informed deep learning super-resolution techniques for enhancing automated optical inspection (AOI) systems in semiconductor manufacturing. As the industry transitions to sub-5nm process nodes, conventional optical inspection faces fundamental diffraction limits preventing detection of critical 3-7nm defects.

### Research Objectives

- **Primary Goal**: Develop physics-informed SR methods that enhance optical inspection images toward electron microscopy quality while maintaining metrological accuracy
- **Target Performance**:
  - >3dB PSNR improvement over traditional deconvolution
  - <5% critical dimension measurement error
  - >95% defect detection recall
  - Successful sim-to-real transfer (>85% performance retention)

### Key Innovations

1. **Physics-Informed Architecture**: Integration of optical system models (PSF/OTF) into neural network architectures and loss functions
2. **Semiconductor-Specific Benchmarking**: First comprehensive benchmark for SR evaluation on semiconductor patterns
3. **Hallucination Mitigation**: Multi-modal detection strategies to ensure metrological fidelity
4. **Uncertainty Quantification**: Confidence estimation for automated decision-making

---

## ğŸ“Š Current Project Status

**Phase**: Phase 1 - Foundation Development (29% Complete)
**Timeline**: 13-18 month master's thesis project
**Current Progress**: Month 1, Week 2 Complete
**Last Updated**: 2025-10-15

### âœ… Completed

#### Week 1: Environment Setup (2025-10-08)
- [x] Comprehensive research proposal (74KB detailed analysis)
- [x] System architecture design
- [x] Technology stack selection
- [x] Development workflow definition
- [x] Success metrics establishment
- [x] Complete project structure (80+ directories)
- [x] Environment setup (requirements.txt, environment.yml)
- [x] Git configuration (.gitignore, .gitattributes, LICENSE)
- [x] Configuration files (5 comprehensive YAML files)

#### Week 2: Pattern Generation (2025-10-15)
- [x] **Pattern generator module** (`src/data/synthetic/pattern_generator.py`)
  - [x] 3 pattern types: gratings, contact holes, isolated features
  - [x] Line edge roughness (LER) modeling
  - [x] Corner rounding for lithographic realism
  - [x] Comprehensive input validation
  - [x] Factory pattern implementation
- [x] **Visualizer module** (`src/data/synthetic/visualizer.py`)
  - [x] 4 visualization modes (simple, profile, stats, multi-pattern)
  - [x] Physical scale display (nanometers)
- [x] **Unit tests**: 39 tests, 100% passing
- [x] **Demo script**: 7 example scenarios
- [x] **Documentation**: Progress report + Quick Start Guide

### ğŸ”„ In Progress (Week 3)
- [ ] PSF/OTF modeling (Airy disk, Hopkins formulation)
- [ ] Image degradation pipeline (convolution + noise)
- [ ] Batch dataset generation

### â³ Upcoming (Week 4)
- [ ] Baseline methods (Richardson-Lucy, Wiener filtering)
- [ ] Evaluation metrics framework
- [ ] First 5,000 synthetic image pairs generated

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Input: Low-Res Optical Image              â”‚
â”‚                   + Optical System Parameters               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Physics-Informed SR Models                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  U-Net   â”‚  RCAN   â”‚ ESRGAN   â”‚ SwinIR  â”‚   HAT    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                              â”‚
â”‚  Physics Components:                                         â”‚
â”‚  â€¢ PSF/OTF Models                                           â”‚
â”‚  â€¢ Optical Parameter Conditioning                            â”‚
â”‚  â€¢ Physics-Informed Loss Functions                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Output: Super-Resolved Image                    â”‚
â”‚              + Uncertainty Map                               â”‚
â”‚              + Hallucination Detection                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

- **Data Pipeline**: Synthetic pattern generation + real microscope data
- **Physics Modeling**: PSF/OTF simulation for optical degradation
- **Model Zoo**: 6 baseline SR architectures
- **Training**: Physics-informed loss functions with optical constraints
- **Evaluation**: Standard + semiconductor-specific metrics
- **Analysis**: Uncertainty quantification, hallucination detection

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10 or higher
- CUDA-capable GPU (recommended: RTX 3060+ for development)
- 16GB+ system RAM
- ~50GB storage for development

### Installation

```bash
# Clone the repository
git clone https://github.com/siamet/semicon-super-resolution.git
cd semicon-super-resolution

# Option 1: Conda environment (recommended)
conda env create -f environment.yml
conda activate semicon-sr

# Option 2: Pip in virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt

# Install package in editable mode
pip install -e .

# Verify installation
python -c "import torch; print(f'PyTorch {torch.__version__}, CUDA: {torch.cuda.is_available()}')"
python -c "import src; print('Package structure ready!')"
```

### Run Pattern Generation Demo

```bash
# Run all demos (interactive mode)
python scripts/demo_pattern_generation.py

# Run specific demo
python scripts/demo_pattern_generation.py --demo 3  # LER comparison

# Save outputs to directory
python scripts/demo_pattern_generation.py --save-path results/demo_output

# Run unit tests
pytest tests/data/synthetic/test_pattern_generator.py -v
```

### Generate Custom Patterns

```python
from src.data.synthetic.pattern_generator import PatternConfig, GratingGenerator
from src.data.synthetic.visualizer import PatternVisualizer

# Configure and generate
config = PatternConfig(image_size=512, pixel_size_nm=2.0)
generator = GratingGenerator(config)
pattern, metadata = generator.generate(
    pitch_nm=80.0,
    duty_cycle=0.5,
    add_ler=True,
    ler_sigma_nm=2.0
)

# Visualize
visualizer = PatternVisualizer()
visualizer.visualize_pattern(pattern, metadata, show_physical_scale=True)
```

See [Pattern Generator Quick Start Guide](docs/PATTERN_GENERATOR_QUICKSTART.md) for detailed usage examples.

### Train Models

```bash
# Train baseline traditional methods
python scripts/training/train_traditional.py \
    --method richardson_lucy \
    --data_dir data/processed/train

# Train deep learning models
python scripts/training/train_deep_models.py \
    --model swinir \
    --config config/training_config.yaml \
    --checkpoint_dir models/checkpoints

# Train with physics-informed loss
python scripts/training/train_deep_models.py \
    --model swinir \
    --config config/training_config.yaml \
    --physics_informed \
    --wavelength 248 \
    --NA 0.95
```

### Evaluate Performance

```bash
# Run comprehensive benchmark
python scripts/evaluation/run_benchmark.py \
    --checkpoint models/final/swinir_best.pth \
    --test_data data/processed/test \
    --output_dir results/benchmarks

# Compare multiple methods
python scripts/evaluation/compare_methods.py \
    --methods unet rcan esrgan swinir \
    --test_data data/processed/test
```

---

## ğŸ“ Project Structure

```
semicon-super-resolution/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ RESEARCH_PROPOSAL.md              # Comprehensive research proposal
â”œâ”€â”€ CLAUDE.md                         # AI development context
â”œâ”€â”€ requirements.txt                  # Python dependencies
â”œâ”€â”€ environment.yml                   # Conda environment
â”‚
â”œâ”€â”€ config/                          # Configuration files
â”‚   â”œâ”€â”€ data_config.yaml            # Data generation parameters
â”‚   â”œâ”€â”€ model_config.yaml           # Model hyperparameters
â”‚   â””â”€â”€ training_config.yaml        # Training configurations
â”‚
â”œâ”€â”€ src/                            # Source code (to be implemented)
â”‚   â”œâ”€â”€ data/                       # Data pipeline
â”‚   â”œâ”€â”€ models/                     # SR model implementations
â”‚   â”œâ”€â”€ physics/                    # PSF/OTF modeling
â”‚   â”œâ”€â”€ training/                   # Training infrastructure
â”‚   â”œâ”€â”€ evaluation/                 # Metrics and benchmarking
â”‚   â””â”€â”€ analysis/                   # Analysis tools
â”‚
â”œâ”€â”€ scripts/                        # Executable scripts
â”‚   â”œâ”€â”€ data_generation/           # Data generation
â”‚   â”œâ”€â”€ training/                  # Training scripts
â”‚   â”œâ”€â”€ evaluation/                # Evaluation scripts
â”‚   â””â”€â”€ analysis/                  # Analysis scripts
â”‚
â”œâ”€â”€ notebooks/                      # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_baseline_analysis.ipynb
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ docs/                          # Documentation
â”‚   â”œâ”€â”€ architecture/              # Architecture design
â”‚   â”œâ”€â”€ installation.md           # Setup instructions
â”‚   â””â”€â”€ api_reference/            # API documentation
â”‚
â”œâ”€â”€ data/                          # Data directory (gitignored)
â”‚   â”œâ”€â”€ raw/                       # Raw data
â”‚   â””â”€â”€ processed/                 # Processed datasets
â”‚
â”œâ”€â”€ models/                        # Trained models (gitignored)
â”‚   â”œâ”€â”€ checkpoints/              # Training checkpoints
â”‚   â””â”€â”€ final/                    # Final models
â”‚
â”œâ”€â”€ results/                       # Experimental results
â”‚   â”œâ”€â”€ benchmarks/               # Benchmark results
â”‚   â”œâ”€â”€ figures/                  # Generated figures
â”‚   â””â”€â”€ logs/                     # Training logs
â”‚
â””â”€â”€ tests/                         # Unit tests
    â”œâ”€â”€ test_data/
    â”œâ”€â”€ test_models/
    â””â”€â”€ test_evaluation/
```

---

## ğŸ”¬ Research Methodology

### Phase 1: Foundation (Months 1-2)
- Synthetic data pipeline development
- Baseline method implementation
- Evaluation framework establishment

### Phase 2: Model Development (Months 3-6)
- Core CNN models (U-Net, RCAN, ESRGAN)
- Advanced transformers (SwinIR, HAT)
- Physics-informed modifications

### Phase 3: Training & Validation (Months 7-10)
- Hyperparameter optimization
- Synthetic benchmarking
- Real-world validation on microscope data

### Phase 4: Analysis & Synthesis (Months 11-13)
- Failure mode analysis
- Uncertainty quantification
- Thesis writing and publication

---

## ğŸ“Š Evaluation Metrics

### Standard Image Quality
- **PSNR** (Peak Signal-to-Noise Ratio)
- **SSIM** (Structural Similarity Index)
- **LPIPS** (Learned Perceptual Image Patch Similarity)

### Semiconductor-Specific
- **CD Error**: Critical dimension measurement accuracy
- **EPE**: Edge placement error
- **Defect Detection**: Precision, recall, F1 score
- **Hallucination Rate**: False feature generation

---

## ğŸ› ï¸ Technology Stack

- **Deep Learning**: PyTorch 2.1.0, torchvision
- **Vision Transformers**: timm (PyTorch Image Models)
- **Scientific Computing**: numpy, scipy, scikit-image
- **Image Processing**: OpenCV, tifffile
- **Optical Simulation**: Custom PSF/OTF models
- **Experiment Tracking**: Weights & Biases, TensorBoard
- **Deployment**: ONNX Runtime, TensorRT

---

## ğŸ“š Key References

1. Liang et al., "SwinIR: Image Restoration Using Swin Transformer" (ICCV 2021)
2. Wang et al., "Real-ESRGAN: Training Real-World Blind Super-Resolution" (ICCV 2021)
3. Chen et al., "HAT: Hybrid Attention Transformer for Image Restoration" (2023)
4. Ren et al., "Physics-informed Deep Super-resolution for Spatiotemporal Data" (JCP 2023)
5. Kim et al., "Electron Microscopy-based Automatic Defect Inspection" (arXiv 2024)

See [RESEARCH_PROPOSAL.md](RESEARCH_PROPOSAL.md) for comprehensive literature review.

---

## ğŸ“ Academic Context

**Type**: Master's Thesis Research  
**Duration**: 13-18 months
**Field**: Computer Vision Ã— Semiconductor Manufacturing    
**Institution**: National Taiwan University     
**Advisor**: Dr. Liang Chia Chen

### Expected Outcomes
- Master's thesis document
- 2-4 peer-reviewed publications
- Open-source software package
- Pre-trained model weights
- Comprehensive benchmarking dataset

---

## ğŸ“ˆ Success Criteria

**Technical Performance**:
- âœ“ >3dB PSNR improvement over deconvolution
- âœ“ <5% CD measurement error
- âœ“ >95% defect detection recall
- âœ“ >10 fps inference on single GPU

**Scientific Contribution**:
- âœ“ First semiconductor-specific SR benchmark
- âœ“ Physics-informed methodologies
- âœ“ Hallucination mitigation strategies
- âœ“ Uncertainty quantification framework

**Practical Impact**:
- âœ“ Successful sim-to-real transfer
- âœ“ Production-ready deployment pipeline
- âœ“ Industry collaboration/validation
- âœ“ Open-source community adoption

---

## ğŸ¤ Contributing

This is a research project for a master's thesis. While direct code contributions are not being accepted at this time, feedback, suggestions, and discussions are welcome:

- **Issues**: Report bugs or suggest features via GitHub Issues
- **Discussions**: Join technical discussions in GitHub Discussions
- **Citations**: If you use this work, please cite appropriately (citation format TBD)

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- Thesis advisor and research group
- Semiconductor industry partners for data and validation
- Open-source community for foundational models (SwinIR, ESRGAN, etc.)
- Funding sources (to be acknowledged)

---

## ğŸ“ Development Notes

For comprehensive research background and methodology, see [RESEARCH_PROPOSAL.md](RESEARCH_PROPOSAL.md).

For system architecture and design patterns, see [docs/architecture/ARCHITECTURE.md](docs/architecture/ARCHITECTURE.md).

For detailed development context and AI collaboration guidelines, see [CLAUDE.md](CLAUDE.md).

---

**ğŸš§ Note**: This project is in the early planning phase. The codebase is currently being implemented based on the completed architecture design. Check back for updates as development progresses!
